## 11.1 성능에 대해

- 여러 개의 스레드를 사용한다면 단일 스레드 사용시보다 성능상의 비용을 지불해야한다
    - 스레드 간의 작업 내용 조율에 필요한 오버헤드(락 걸기, 신호 보내기, 메모리 동기화하기 등)
    - 컨텍스트 스위칭의 빈번할 발생
    - 스레드 생성 제거의 빈번함
    - 여러 스레드의 효율적인 스케쥴링 등
- 더 나은 성능을 목표로 프로그램이 병렬적으로 동작하게 만들 때의 필요한 2개의 우선 순위
    - **프로그램이 확보할 수 있는 모든 자원을 최대한 활용해야 한다**
    - **남는 자원이 생길 때마다 그 자원 역시 최대한 활용할 수 있도록 해야한다**

### 11.1.1 성능 대 확장성

- 확장성(scalability)
    - CPU, 메모리, 디스크, I/O 처리 장치 등의 추가적인 장비를 사용해 처리량이나 용량을 얼마나 쉽게 키울 수 있는지
    - 단일 구조의 어플리케이션 vs 3-Tier 어플리케이션
        - 단일 구조의 어플리케이션가 더 빠름 ⇒ 3-Tier 어플리케이션의 경우 서로 다른 티어 간에 작업을 주고받는 동안 네트워크 시간 지연 현상, 서로 다른 추상 계층 간 처리 비용 등이 필요하기 때문
        - 단일 구조 애플리케이션이 처리할 수 있는 최대 부하를 넘어설 경우 서비스의 시간이 길어져, 문제가 발생한다

### 11.1.2 성능 트레이드 오프 측정

- **최적화 기법을 너무 이른 시점에 적용하지 말아야 한다. 일단 제대로 동작하게 만들고 난 다음에 빠르게 동작하도록 최적화해야 하며, 예상한 것보다 심각하게 성능이 떨어지는 경우에만 최적화 기법을 적용하는 것만으로도 충분하다**
- 성능을 튜닝하는 모든 과정에서 항상 성능 목표에 명확한 요구 사항이 필요하다며, 실제로 이를 축정 해야한다
- 성능을 높이기 위한 결정 사항에 대한 질문
    - “빠르다” 단어가 무엇을 의미하는가?
    - 어떤 조건을 갖춰야 이 방법이 실제로 ‘빠르게’ 동작할 것인가? 부하가 적을 때? 아니면 부하가 걸릴 때? 데이터가 많을 때? 적을 때? 이런 질문에 대한 대답에 명확한 수치를 보여줄 수 있는가?
    - 위의 조건에 해당하는 경우가 얼마나 많이 발생하는가? 이런 질문에 대한 대답에 명확한 수치를 보여줄 수 있는가?
    - 조건이 달라지는 다른 상황에서도 같은 코드를 사용할 수 있는가?
    - 이 방법을 성능을 개선하고자 할 때, 숨겨진 비용, 즉 개발 비용이나 유지 보수 비용이 증가하는 부분이 어느 정도인가? 과연 그런 비용을 감수하면서까지 성능 개선 작업을 해야하는가?
- 병렬 프로그래밍에서 발생하는 오류 중 원인
    - 성능을 높이려는 여러 가지 기법에서 비롯

## 11.2 암달의 법칙

- **모든 병렬 프로그램에는 항상 순차적으로 실행돼야만 하는 부분이 존재한다. 만약 그런 부분이 없다고 생각한다면, 프로그램 코드를 다시 한 번 들여다보라**
- 암달의 법칙(amdahl’s law)
    - 병렬 작업과 순차 작업의 비율에 따라 하드웨어 자원을 추가로 투입했을 때 이론적으로 속도가 얼마나 빨라질지에 대한 예측값
    - 프로세서의 개수가 증가하면 할 수록, 순차적으로 실행해야 하는 부분이 아주 조금이라도 늘어나면 프로세서 개수에 비해 얻을 수 있는 속도 증가량이 크게 떨어진다
        - 이론적으론 프로세서를 더 꽂을수록 더 많은 작업을 병렬적으로 실행할 수 있지만**, 작업 큐에서 작업을 하나씩 뽑는 부분은 순차적으로 처리해야**만 한다
        - **단위 작업의 처리 결과를 취합하는 과정도 순차적인 처리가 필요**
    - S(n) = 1 / ( (1 - p) + (p/n) )
        - S(n)은 전체 시스템의 이론적 속도 향상(speedup)
        - n은 프로세서의 수(또는 병렬화 정도)
        - p는 프로그램에서 병렬화 가능한 부분의 비율

### 11.2.1 예제: 프레임웍 내부에 감춰져 있는 순차적 실행 구조

- ConcurrentLinkedQueue
    - 처리량이 계속 증가하다가 프로세서의 개수에 해당하는 수치에 다다르면 더 이상 증가하지 않고 일정하게 유지
    - 정교한 큐 알고리즘, 개별 링크 포인터마다 단일 연산으로 업데이트하는 방법을 사용해 대기 상태에 들어가는 경우를 최소화
    - 개별 포인터에 대한 업데이트 연산만 순차적으로 처리
- LinkedList
    - 스레드가 3개 정도까지는 증가하다가 그 이후에는 동기화 관련 부하가 늘어나 성능이 떨어짐.
    - 스레드 개수가 4개나 5개만 돼도 스레드 간에 큐에 들어 있는 락을 차지하려는 경쟁이 치열해지면서 컨텍스트 스위칭을 하느라 성능에 큰 영향을 준다
    - 동기화된 LinkedList는 전체 큐의 상태를 하나의 락으로 동기화하고 있으며, offer나 remove 메소드를 호출하는 동알 전체 큐가 모두 락에 걸린다
    - 추가 작업과 삭제 모두 순차적으로 처리

### 11.2.2 정성적인 암달의 법칙 적용 방법

- 수백 개 또는 수천 개의 프로세서가 동작하는 상황까지 가정한 상태에서 프로그램의 알고리즘 평가한ㄷ가면, 어느 시점쯤에서 확장성의 한계가 나타날 것인지 예측 가능

## 11.3 스레드와 비용

### 11.3.1 컨텍스트 스위칭

- 컨텍스트 스위칭
    - 하나의 스레드가 실행되다가 다른 스레드가 실행되는 순간 컨텍스트 스위칭 발생
    - 현재 실행 중인 스레드의 실행 상태를 보관해두고, 다음 번에 실행되기로 스케줄된 다른 스레드의 실행 상태를 다시 읽어드림
    - 스레드 스케줄링을 하려면 운영체제와 JVM 내부의 공용 자료 구조를 다뤄야함
    - 컨텍스트 변경 시 다른 스레드를 실행하려면 해당 스레드가 사용하던 데이터가 프로세서의 캐시 메모리에서 가져오지 못하고 다른 보관소에서 데이터를 찾아야해 실행 시간이 느려짐
    - 대부분은 이를 막기 위해 실행 대기 중인 스레드가 밀려 있다 해도 현재 실행 중인 스레드에게 최소한의 실행 시간을 보장해줌
    - 스레드가 실행하다 락을 확보하기 위해 대기를 시작하면, 일반적으로 JVM은 해당 스레드를 일시적으로 정지시키고 다른 스레드가 실행되도록 함
    - 태기 상태에 들어가는 연산을 많이 사용하는 프로그램(블로킹 I/O 사용, 락 대기 시간이 길거나, 상태 변수의 값을 기다리는 등)은 CPU를 주로 활용하는 프로그램보다 컨텍스트 스위칭 횟수가 훨씬 많아지고, 스케줄링 부하가 늘어나면서 전체적인 처리량이 줄어듦

### 11.3.2 메모리 동기화

- synchronized, volatile 키워드를 사용해 얻을 수 있는 가시성을 통해 메모리 배리어라는 특별한 명령어를 사용할 수 있다
- 메모리 배리어
    - 캐시를 플러시하거나 무효화하고, 하드웨어와 관련된 쓰기 버퍼를 플러시하고, 실행 파이프라인을 늦출 수도 있다
    - 메모리 배리어를 사용하면 컴파일러가 제공하는 여러 가지 최적화 기법을 제대로 사용할 수 없게 돼 간접적인 성능 문제를 가져올 수 있다
- 최근 JVM은 대부분 다른 스레드와 경쟁할 가능성이 없다고 판단되는 부분에 락이 걸려 있다면 최적화 과정에서 해당 락을 사용하지 않도록 방지하는 기능을 제공하기도 함
- 훨씬 정교하게[ 만들어진 JVM의 경우 유출 분석(escape analysis)을 통해 로컬 변수가 스레드 내부에서만 사용되는지 판단하기도 함
    - 예시 - stooges 변수를 락 없이 실행
        
        ```Java
        public String getStoogeNames() {
        	List<String> stooges = new Vector<String>();
        	stooges.add("Moe");
        	stooges.add("Moe1");
        	stooges.add("Moe2");
        	return stooges.toString();
        }
        ```
        
- 유출 분석을 사용하지 않는 경우라면, 락 확장?(lock coarsening)을 사용
    - 연달아 붙어 있는 여러 개의 synchronized 블록을 하나의 락으로 묶는 방법을 사용하기도 함
- 경쟁 조건에 들어가지않는 동기화 블록에 대해서는 그다지 걱정하지 않아도 된다. 동기화 블록의 기본적인 구조가 상당히 빠르게 동작할 뿐만 아니라 JVM 수준에서 동기화와 관련한 추가적인 최적화 작업을 진행하기 때문에 동기화 관련 부하를 줄이거나 아예 없애주기도 한다. 대신 경쟁 조건이 발생하는 동기화 블록을 어떻게 최적화할지에 대해 고민하자.
- 특정 스레드에서 진행되는 동기화 작업으로 인해 다른 스레드의 성능이 영향을 받을 수도 있다
    - 동기화 작업은 공유돼 있는 메모리로 통하는 버스에 많은 트래픽을 유발하기 때문이다
    - 공유 메모리로 통하는 버스는 제한적인 대역폭을 가지고 있고, 여러 개의 프로세서가 공유
    - 특정 스레드가 도ㅑ기화 작업ㅇ르 진행하느라 공유 메모리로 통하는 버스의 대역폭을 꼬가 잡고 있다면, 동기화 작업을 진행해야 할 다른 스레드는 성능이 떨어질 수 밖에 없다

### 11.3.3 블로킹

- 락을 놓고 경쟁하고 있다면, 락을 확보하지 못한 스레드는 항상 대기 상태에 들어가야 한다.
- JVM이 스레드를 대기 상태로 두는 방법
    - 스핀 대기
        - 락을 확보할 때까지 계속해서 재시도
        - 대기 상태가 짧을 경우 효과적
    - 운영체제가 제공하는 기능 사용
        - 실제 대기 상태로 두기
        - 대기 상태가 긴 경우
- 락을 확보하지 못했거나 I/O 관련 작업ㅇ르 사용 중이라거나 기타 여러 가지 조건에 걸려 스레드가 대기 상태에 들어갈 때는 두 번의 컨텍스트 스위칭 작업이 발생하며, 이 과정에서 운영체제와 각종 캐시 등의 모듈이 연결되어 있다
    - 첫 번째 컨텍스트 스위칭은 실행하도록 할당된 시간 이전에 대기 상태에 들어가느라 발생
    - 두 번째 컨텍스트 스위칭은 락이나 기타 필요한 조건이 충족됐을 때 다시 실행 상태로 돌아오는 컨텍스트 스위칭

## 11.4 락 경쟁 줄이기

> [!important]  
> 병렬 애플리케이션에서 확장성에 가장 큰 위협이 되는 존재는 바로 특정 자원을 독점적으로 사용하도록 제한하는 락  

- 락 경쟁 조건을 줄일 수 있는 방법
    - 락을 확보한 채로 유지되는 시간을 최대한 줄여라
    - 락을 확보하고자 요청하는 횟수를 최대한 줄여라
    - 독점적인 락 대신 병렬성을 크게 높여주는 여러 가지 조율 방법을 사용하라

### 11.4.1 락 구역 좁히기

- 락이 꼭 필요하지 않은 코드를 synchronized 블록 밖으로 뽑아내 락이 영향을 미치는 구역을 좁히면 락을 유지하는 시간을 최대한 줄일 수 있다
- 락 점유 시간 단축 예시 코드
    
    ```Java
    @ThreadSafe
    public class BetterAttributeStore {
    	@GuardedBy("this")
    	private final Map<String, String> attributes = new HashMap<>();
    	
    	public boolean userLocationMatches(String name, String regexp) {
    		String key = "Users." + name + ".locations";
    		String location;
    		synchronized(this) {
    			location = attributes.get(key);
    		}
    		if(location == null ) {
    			return false;
    		}else{
    			return Pattern.matches(regexp, location);
    		}
    	}
    }
    ```
    

### 11.4.2 락 정밀도 높이기

- 락 분할과 락 스트라이핑
    - 하나의 락으로 여러 개의 상태 변수를 한번에 묶어두지 않고, 서로 다른 락을 사용해 여러 개의 독립적인 상태 변수를 각자 묶어 두는 방법을 통해 락 정밀도를 높힐 수 있다
    - 락으로 묶이는 프로그램의 범위를 조밀하게 나눌 수 있어, 애플리케이션의 확장성이 높아짐
    - 락의 개수가 많아질수록 데드락이 발생할 가능성이 있음
    - 락이 분할된 ServerStatus 클래스
        
        ```Java
        @ThreadSafe
        public class ServerStatus {
        	@GuardedBy("users")
        	public final Set<String> users;
        	
        	@GuardedBy("queries")
        	public final Set<String> queries;
        	
        	public void addUser(String u) {
        		synchronized (users) {
        			users.add(u);
        		}
        	}
        	
        	public void addQuery(String q) {
        		synchronized (queries) {
        			queries.add(q);
        		}
        	}
        }
        ```
        

  

### 11.4.3 락 스트레이핑

- 독립적인 객체를 여러 가지 크기의 단위로 묶어내고, 묶인 블록을 단위로 락을 나누는 방법
- 락 스트라이핑을 사용하면, 여러 개의 락을 사용하도록 쪼개놓은 컬렉션 전체를 한꺼번에 독점적으로 사용해야할 필요가 있을 수 있는데, 이런 경우 단일 락을 사용할 때보다 동기화가 어렵고 자원도 많이 소모하는 단점이 있음

### 11.4.4 핫 필드 최소화

- 핫 필드
    - 모든 연산을 수행할 때마다 한 번씩 사용해야 하는 부분
    - 모든 연산에 꼭 필요한 변수가 있다면 락의 정밀도를 세밀하게 쪼개는 방법을 적용할 수 없음
    - 예를 들어 자주 계산하고 사용하는 값을 캐시에 저장해두도록 최적화하면 확장성을 떨어뜨릴 수 밖에 없는 ‘hot field’가 발생

### 11.4.5 독점적인 락을 최소화하는 다른 방법

- 좀 더 높은 병렬성으로 공유된 변수를 관리하는 방법 도입을 통한 독점적 락을 줄이는 방법
    - 병렬 컬렉션 클래스 사용
    - read-write 락 사용
    - 불변 객체 사용
    - 단일 연산 변수 사용(atomic variable)
        - 핫 필드 값을 손쉽게 변경가능하게 함

### 11.4.6 CPU 활용도 모니터링

- CPU가 충분하게 사용되지 못하게 하는 원인
    - 부하가 부족하다
        - 테스트하는 프로그램이 CPU 사용량을 측정할만큼 충분한 부하 상황을 만들지 않은 것
    - I/O 제약
    - 외부 제약 사항
        - 애플리케이션에서 외부 데이터베이스 또는 웹 서비스 등을 사용하고 있다면 성능의 발목을 잡는 병목이 외부에 있을 가능성도 높음
    - 락 경쟁

### 11.4.7 객체 풀링은 하지 말자

- 병렬 애플리케이션에서 객체 풀링을 사용했을 때 훨씬 많은 비용을 지불해야할 수도 있다
- 스레드 내부에서 필요로 하는 객체를 새로 생성할 때에는 힙 데이터 구조를 사용할 때 동기화해야 하는 부분을 건너뛸 수 있도록 스레드 내부의 할당 블록을 사용하기 때문에 스레드 간에 조율해야 할 일이 거의 없다
- 스레드 동기화하느 것보다 메모리에 객체를 할당하는 일이 훨씬 부담이 적다

## 11.5 예제 : Map 객체의 성능 분석

- 단일 스레드 환경에서 synchronizedMap, ConcurrentHashMap은 대등한 속도를 보여주지만, 경쟁 조건이 발생하지 않는 상황에서 경쟁이 발생하는 상황으로 넘어가면 synchronizedMap의 성능이 급격히 저하한다

## 11.6 컨텍스트 스위치 부하 줄이기

- 요청을 처리한느 스레드의 외부로 I/O 작업을 뽑아내는 방법을 통해 요청 처리의 평균 시간 줄여주기
