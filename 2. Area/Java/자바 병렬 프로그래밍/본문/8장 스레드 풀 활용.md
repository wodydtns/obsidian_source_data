## 8.1 작업과 실행 정책 간의 보이지 않는 연결 관계

- 일정한 조건을 갖춘 실행 정책이 필요한 작업
    - 의존성이 있는 작업
        - 독립적인 작업은 대부분 문제 없이 잘 동작
        - 다른 작업에 의존성을 갖는 작업을 스레드 풀에 올려 실행하려는 경우 활동성 문제(liveness problem)이 발생하지 않도록 하려면 실행 정책에 대한 조건을 조사 관리해야한다
    - 스레드 한정 기법을 사용하는 작업
        - 단일 스레드 작업은 등록된 작업에 대한 동시성 문제가 없어 작업 정의 내용을 훨씬 쉽게 구현 가능
            - 작업에서 사용하는 객체를 스레드 수준에 맞춰 한정 지을 수 있고, 같은 스레드에 한정된 객체라면 해당 객체가 스레드 안전성을 갖추고 있지 않다해도 얼마든지 마음대로 사용 가능
            - 해당 작업을 실행하려면 Executor 프레임워크가 단일 스레드로 동작해야한다는 조건이 생겨 작업과 실행 정책 간에 보이지 않는 연결 고리가 걸린 상황
        - 이를 스레드 풀로 변경하면 스레드 안전성을 쉽게 잃을 수 있다
    - 응답 시간이 민감한 작업
        - 단일 스레드로 동작하는 Executor에 오랫동안 실행될 작업을 등록하거나, 서너개의 스레드로 동작하는 풀에 실행 시간이 긴 작업을 몇개만 등록해도 응답 성능이 떨어짐
    - ThreadLocal을 사용하는 작업
        - Executor는 상황이 되는대로 기존 스레드를 최대한 재사용
        - ThreadLocal은 현재 실행 중인 작업이 끝나면 더 이상 사용하지 않을 값만 보관해 ThreadLocal의 특성을 이용해 작업 간에 값을 전달하는 용도로 사용해서는 안된다
    - **스레드 풀은 동일하고 서로 독립적인 다수의 작업을 실행할 때 가장 효과적**
    - 다른 작업에 의존성이 있는 작업을 실행해야할 때는 스레드 풀의 크기를 충분히 크게 잡아 작업이 큐에서 대기하거나 등록되지 못하는 상황이 없도록 해야한다
    - 스레드 한정 기법을 사용하는 작업은 반드시 순차적으로 실행돼야 한다
    - 작업을 구현할 때는 나중에 유지보수를 진행할 때 해당 작업과 호환되지 안흔 실행 정책 아래에서 실행하도록 변경해 애플리케이션의 안전성을 해치거나 실행되지 않는 경우를 막을 수 있도록 실행 정책과 관련된 내용을 문서로 남겨야 한다

### 8.1.1 스레드 부족 데드락

- 스레드 풀에서 다른 작업에 의존성을 갖고 있는 작업을 실행시킨다면 데드락에 걸릴 가능성이 높다
- 스레드 부족 데드락(thread starvation deadlock)
    - 단일 스레드로 동작하는 Executor에서 다른 작업을 큐에 등록하고 해당 작업이 실행된 결과를 가져다 사용하는 작업을 실행하면, 데드락에 걸린다
        - 이전 작업이 추가한 두 번째 작업은 큐에 쌓인 상태로 이전 작업이 끝날때까지 대기
        - 이전 작업은 추가된 작업이 실행되어 그 결과를 받을 때까지 대기
    - 특정 자원을 확보하고자 계속해서 대기하거나 풀 내부의 다른 작업이 실행돼야 알 수 있는 조건이 만족하기를 기다리는 것처럼 끝없이 계속 대기할 가능성이 있는 기능을 사용하는 작업이 풀에 등록된 경우 언제든 발생할 수 있음
- 단일 스레드 Executor에서 데드락이 발생하는 작업 구조. **- 이런 코드는 금물!**
    
    ```Java
    public class ThreadDeadLock {
    	ExecutorService exec = Executors.newSingleThreadExecutor();
    	
    	public class RenderPageTask implements Callable<String> {
    		public String call() throws Exception {
    			Future<String> header, footer;
    			header = exec.submit(new LoadFileTask("header.html");
    			footer = exec.submit(new LoadFileTask("footer.html");
    			String page = renderBody();
    			// 데드락 발생
    			return header.get() + page + footer.get();
    		}
    	}
    }
    ```
    
    - 완전히 독립적이지 않은 작업을 Executor에 등록할 때 항상 스레드 부족 데드락이 발생할 수 있다는 사실을 염두해야하며, 작업을 구현한 코드나 Executor를 설정하는 설정 파일 등에 항상 스레드 풀의 크기나 설정에 대한 내용을 설명해야한다

### 8.1.2 오래 실행되는 작업

- 데드락이 발생하지 않는다 하더라도, 특정 작업이 예상보다 긴 시간동안 종료되지 않고 실행된다면 스레드 풀의 응답 속도에 문제가 생긴다
- 오래 실행되는 작업이 있다면 스레드 풀은 전체적인 작업 실행 과정에 어려움을 겪고 금방 끝나는 작업이 실행되는 속도에도 영향을 미친다
- 제한 없이 계속 대기하는 기능 대신 일정 시간 동안만 대기하는 메소드를 사용할 수 있다면, 오래 실행되는 작업이 주는 악영향을 줄일 수 있다
    - 예시
        - Thread.join, BlockingQueue.put, CountDownLatch.await, Selector.select
    - 대기 도중 지정한 시간이 지나면 해당 작업이 제대로 실행되지 못했다는 기록을 해두고, 일단 종료시킨다음 다음 큐의 맨 뒤에 다시 추가하는 등의 대첵을 세울 수 있다

## 8.2 스레드 풀 크기 조절

- 스레드 풀의 크기가 적절해야한다
    - 스레드 풀이 너무 크면 CPU나 메모리 등의 자원을 조금이라도 더 확보하기 위해 경쟁해 자원 부족에 시달림
    - 스레드 풀이 너무 작으면 작업량은 쌓이고, CPU나 메모리가 남아돌아 작업 처리 속도가 느려지는 문제가 있음
- CPU를 많이 사용하는 작업의 경우 N개의 CPU를 탑재하고 있는 하드웨어에서 스레드 풀을 사용할 때 스레드의 개수를 N+1개로 맞추면 최적의 성능을 발휘한다고 알려져 있다
- 참고
    - CPU 코어 수 기반 공식:
        - 계산 집약적 작업: 스레드 수 = CPU 코어 수
        - I/O 집약적 작업: 스레드 수 = CPU 코어 수 * (1 + 대기 시간 / 서비스 시간)
    - Little의 법칙
        - 스레드 수 = 초당 요청 수 * 평균 응답 시간
    - 경험적 공식
        - 스레드 수 = CPU 코어 수 * (1 + 대기 시간 비율)
        - 여기서 대기 시간 비율은 작업의 대기 시간과 CPU 사용 시간의 비율입니다.
    - 실험적 접근
        - 다양한 스레드 수로 성능 테스트를 수행하고 최적의 결과를 보이는 값을 선택합니다.

## 8.3 ThreadPoolExecutor 설정

- ThreadPoolExecutor
    

### 8.3.1 스레드 생성과 제거

- 풀의 코어 크기나 최대 크기, 스레드 유지 시간 등의 값을 통해 스레드가 생성되고 제거되는 과정을 조절할 수 있다
- 코어 크기는 스레드 풀을 사용할 때 원하는 스레드의 개수
- 스레드 풀 클래스는 실행할 작업이 없다하더라도 스레드의 개수를 최대한 코어 크기에 맞추도록 되어 있고, 큐에 작업이 가득차지 않는 이상 스레드의 수가 코어 크기를 넘지 않는다
- 풀의 최대 크기는 동시에 얼마나 많은 개수의 스레드가 동작할 수 있는지를 제한하는 최대 값
- 지정한 스레드 유지 시간 이상 아무런 작업 없이 대기하고 있던 스레드는 제거 대상 목록에 올라가며, 풀의 스레드 개수가 코어 크기를 넘어설 때 제거
- ThreadPoolExecutor의 범용 생성 메소드
    
    ```Java
    public ThreadPoolExecutor ( int corePoolSize, int maximumPoolSize,
    														long keeyAliveTime, TimeUnit unit,
    														BlockingQueue<Runnable> workQueue,
    														ThreadFactory threadFactory,
    														RejectedExecutionHandler handler) { ...}
    ```
    
- newFixedThreadPool 팩토리 메소드는 결과로 생성할 스레드 풀의 코어 크기와 최대 크기를 newFixedThreadPool 메소드에 지정한 값으로 동일하게 지정하며, 시간 제한은 무제한으로 설정되는 것과 같다
- newCachedThreadPool 팩토리 메소드는 스레드 풀의 최대 크기를 Integer.MAX_VALUE 값으로 지정하고 코어 크기를 0으로, 스레드 유지 시간을 1분으로 지정
    - newCachedThreadPool에서 만들어낸 스레드 풀은 끝없이 크기가 늘어날 수 있고, 사용량이 줄어들면 스레드 개수가 적당히 줄어드는 효과가 있음

### 8.3.2 큐에 쌓인 작업 관리

- 크기가 제한된 스레드 풀에서는 동시에 실행될 수 있는 스레드의 개수가 제한되어 있다
- 고정된 크기의 스레드 풀을 사용하는 방법도 애플리케이션에 부하가 많이 걸리는 경우 자원을 모두 잡아먹는 상태에 이를 수 있고, 스레드 풀을 사용하지 않는 경우보다 문제가 훨씬 적게 발생할 뿐이다
- 스레드 풀을 사용하는 경우 Executor 클래스에서 관리하는 큐에 Runnable 로 정의된 작업이 계속 쌓일 뿐이고, 스레드 풀 없이 스레드가 계속해서 생성됐을 때 각 스레드가 CPU를 확보하기 위해 대기하는 것과 동일한 상황이 발생
- ThreadPoolExecutor 생성 시 작업을 쌓아둘 큐로 BlockingQueue를 지정할 수 있음
- 스레드 풀에서 작업을 쌓아둘 큐에 적용할 수 있는 전략 세 가지
    - 큐에 크기 제한하지 않음
    - 큐의 크기를 제한
    - 작업을 스레드에게 직접 넘겨주기
- newFixedThreadPool, newSingleThreadExeuctor 메소드에서 생성하는 풀은 기본 설정으로 크기가 제한되지 않은 LinkedBlockingQueue 사용
    - 작업 처리 속도 < 작업 누적 속도면 큐에 끊임없이 작업이 쌓임
- 자원 관리 측면에서 ArrayBlockingQueue, 크기가 제한된 LinkedBlockingQueue, PriorityBlockingQueue와 같이 큐의 크기를 제한시켜 사용하는 방법이 안정적
- 작업 큐의 크기를 제한한 상태에서 큐의 크기와 스레드의 개수를 **동시에 튜닝해야한다**
    - 스레드의 개수는 줄이고 큐의 크기를 늘려주면 메모리와 CPU 사용량을 줄이면서 컨텍스트 스위칭 횟수를 줄일 수 있지만, 전체적인 성능에는 제한이 생길 수 있다
- 스레드 개수가 굉장히 많거나 제한이 거의 없는 상태인 경우 작업을 큐에 쌓는 절차를 생략할 수도 있는데, 이럴 때 SynchronousQueue를 사용해 프로듀서에서 생성한 작업을 컨슈머인 스레드에 직접 전달 가능.
- SynchronousQueue는 따지고 보면 큐가 아니고, 단지 스레드 간에 작업을 넘겨주는 기능을 담당
- SynchronousQueue에 작업을 추가하려면 컨슈머인 스레드가 이미 작업을 받기 위해 대기해야함
- 대기 중인 스레드가 없는 상태에서 스레드의 개수가 최대 크기보다 작다면 ThreadPoolExecutor 는 새로운 스레드를 생성해 동작시킴
- 스레드의 개수가 최대 크기에 다다른 상태라면 집중 대응 정책(saturation policy)에 따라 작업을 거부
- LinkedBlockingQueue, ArrayBlockingQueue와 같은 FIFO 큐를 사용하면 작업이 등록된 순서에 맞춰 실행
- 작업이 실행되는 순서를 조절하고자 한다면 PriorityBlockingQueue 사용해 우선 순위에 따른 실행 배치
- 크기가 고정된 풀보다 newCachedThreadPool 팩토리 메소드가 생성해주는 Executor가 나은 선택일 수 있다. 크기가 고정된 스레드 풀은 자원 관리 측면에서 동시에 실행되는 스레드의 수를 제한해야하는 경우 현명한 선택이다.

### 8.3.3 집중 대응 정책

- ThreadPoolExecutor의 집중 대응 정책은 setRejectedExecutionHandler 메소드를 사용해 원하는 정책을 변경
- setRejectedExecutionHandler 에는 AbortPolicy, CallerRunsPolicy, DiscardPolicy, DiscardOldestPolicy 등
- 기본 집중 대응 정책은 abort(중단) 정책, 중단 시 RejectedExecutionException
- 제거(discard) 정책은 큐에 작업을 더 이상 쌓을 수 없다면 방금 추가했던 정책을 아무 반응 없이 제거
- discard oldest(오래된 항목 제거) 정책은 큐에 쌓은 항목 중 가장 오래되어 다음 번에 실행 예정이던 작업을 제거하고, 추가하고자 했던 작업을 큐에 다시 추가
- caller runs(호출자 실행) 정책은 작업을 제거하거나 예외를 던지지 않으면서 큐의 크기를 초과하는 작업을 프로듀서에게 넘겨 작업 추가 속도를 늦출 수 있도록 일종의 속도 조절 방법 사용
- 스레드의 개수와 작업 큐의 크기가 제한된 스레드 풀을 만들면서 호출자 실행 정책을 지정하는 예제
    
    ```Java
    ThreadPoolExecutor executor = new ThreadPoolExecutor
    								(N_THREADS,N_THREADS, 0L, TimeUnit.MILLISECONDS, 
    								new LinkedBlockingQueue<Runnable>(CAPACITY));
    executor.setRejectedExecutionHandler(
    	new ThreadPoolExecutor.CallerRunsPolicy());
    ```
    

### 8.3.4 스레드 팩토리

- 스레드 팩토리
    - 스레드 풀에서 새로운 스레드를 생성해야 할 시점이 되면, 새로운 스레드는 항상 스레드 팩토리를 통해 생성
    - 기본값으로 설정된 스레드 팩토리에서 데몬이 아니면서 아무런 설정도 변경하지 않은 새로운 스레드를 생성하도록 되어 있다
    - 스레드 팩토리를 직접 작성해 적용하면 스레드 풀에서 사용할 스레드 설정 지정 가능
    - ThreadFactory 클래스에는 newThread라는 메소드 하나만 정의되어 있고, 스레드 풀에서 새로운 스레드를 생성할 때 항상 newThread메소드 호출
- Semaphore를 사용해 작업 시행 속도 조절
    
    ```Java
    @ThreadSafe
    public class BoundExecutor {
    	private final Executor exec;
    	private final Semaphore semaphore;
    	
    	public BoundExecutor(Executor exec, int bound) {
    		this.exec = exec;
    		this.semaphore = new Semaphore(bound);
    	} 
    	
    	public void submitTask(final Runnable command) throws InterruptedException {
    		semaphore.acquire();
    		try {
    			exec.execute(new Runnable() {
    				pulbic void run() {
    					try {
    						command.run();
    					}finally{
    						semapore.release();
    					}
    				}
    			}
    		} catch(RejectedExecutionException e){
    			semaphore.releas();
    		}	
    	}
    }
    ```
    
- ThreadFactory 인터페이스
    
    ```Java
    public interface ThreadFactory {
    	Thread newThread(Runnable r);
    }
    ```
    
- 직접 작성한 스레드 팩토리
    
    ```Java
    public class MyThreadFactory implements ThreadFactory {
    	private final String poolName;
    	
    	public MyThreadFactory(String poolName) {
    		this.poolName = poolName;
    	} 
    	
    	public Thread newThread(Runnable runnable) {
    		return new MyAppThread(runnable, poolName);
    	}
    }
    ```
    
- privilegedThreadFactory
    - privilegedThreadFactory 메소드를 호출한 스레드와 동일한 권한 동일한 AccessControlContext, 동일한 contextClassLoader 결과를 갖는 스레드 생성

### 8.3.5 ThreadPoolExeuctor 생성 이후 설정 변경

- ThreadPoolExecutor를 생성 시 생성 메소드에 넘겨줬던 설정 값은 대부분 여러 가지 set 메소드를 사용해 생성된 이후 변경 가능
- Executors
    - unconfigurableExecutorService
        - 현재 만들어져 있는 ExecutorService를 넘겨 받은 다음 ExecutorService의 메소드만을 외부에 노출하고 더 이상 설정이 불가능하도록 함
    - newSingleThreadExecutor
        - ThreadPoolExecutor 인스턴스를 만들어주는 대신 단일 스레드 기능에 맞춰 wrapper한 ExecutorService를 생성
- 기본 팩토리 메소드로 만들어진 Executor의 설정 변경 모습
    
    ```Java
    ExecutorService exec = Executors.newCachedThreadPool();
    if ( exec instanceof ThreadPoolExecutor) {
    	(( ThreadPoolExecutor) exec).setCorePoolSize(10);
    }else{
    	throw new AssertionError("error");
    }
    ```
    

## 8.4 ThreadPoolExecutor 상속

- ThreadPoolExecutor
    - beforeExecute, afterExecute 메소드는 작업을 실행할 스레드의 내부에서 호출
    - 로그 메시지를 남기거나 작업 실행 시점이 언제인지 기록하거나 실행 상태를 모니터링하거나 통계 값 등의 작업 수행 시 유용
    - afterExecute 훅 메소드는 run 메소드가 정상적으로 종료되거나 예외가 발생해 Exception을 던지고 종료 되는 등의 어떤 상황에서도 항상 호출

## 8.5 재귀 함수 병렬화

- 특정 작업을 여러 번 실행하는 반복문이 있을 때, 반복되는 각 작업이 서로 독립적이라면 병렬화해서 성능의 이점을 얻을 수 있다. 특히 반복문 내부의 작업을 개별적인 작업으로 구분해 실행하느라 추가되는 약간의 부하가 부담되지 않을 만큼 적지 않은 시간이 걸리는 작업이라야 더 효과를 볼 수 있다
- 순차적인 재귀 함수를 병렬화한 모습
    
    ```Java
    public<T> void sequentialRecursive(List<Node<T>> nodes, Collection<T> result) {
    	for (Node<T> n : nodes) {
    		results.add(n.compute());
    		sequentialREcursive(n.getChildren(), results);
    	}
    }
    
    public<T> void parallelRecursive(final Executor exec, List<Node<T>> nodes, 
    																Collection<T> result) {
    		for( final Node<T> n : nodes) {
    			exec.execute(new Runnable(){
    				public void run() {
    					results.add(n.compute());
    				}
    			});
    			parallelRecursive(exec, n.getChildren(), results);
    		}													
    }
    ```
    
- 병렬 연산 작업이 모두 끝나기를 기다리는 예제
    
    ```Java
    public<T> Collection<T> getParallelResults(List<Node<T>> nodes) throws InterruptedException {
    	ExecutorService exec = Executors.newCachedThreadPool();
    	Queue<T> resultQueue = new ConcurrentLinkedQueue<T>();
    	parallelRecursive(exec,nodes,resultQueue);
    	exec.shutdown();
    	exec.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
    	return resultQueue;
    }
    ```
    
