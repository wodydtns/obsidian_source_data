## 3.1 최신 하드웨어 소개

## 3.2 메모리

- 메모리의 최초 방전은 클럭 속도를 높이는 데 사용되었다
- 프로세서의 빨라지는 속도에 비해 메인 메모리는 느렸다
### 3.2.1 메모리 캐시
- 프로세서의 속도를 따라잡기 위해 CPU 캐시를 고안
- CPU 캐시는 CPU에 있는 메모리 영역
- 레지스터보단 느리지만 메인 메모리보단 빠름
- 자주 액세스하는 메모리 위치는 CPU가 메인 메모리를 재참조하지 않게 사본을 떠 CPU 캐시에 보관하자는 아이디어
- 일반적으로 CPU와 가장 가까운 L1, L2 캐시는 각 실행 코어에 전용 프라이빗 캐스로 두고, 일부 또는 전체 코어가 공유하는 L3 캐시를 둠
- 다양한 메모리 종류별 액세스 시간
        ![[Untitled 5 1.png]]
    
- 전체 CPU 및 메모리 아키텍처
        ![[Untitled 6 1.png]]
    
- 캐시 일관성 프로토콜(cache consistency protocol)
    - 메모리에서 데이터를 캐시로 가져오고, 캐시한 데이터를 메모리에 쓰는 방법에 대한 프로토콜
- 프로세서의 가장 저수준에서 일어나는 MESI 프로토콜
    - 캐시 라인(보통 64바이트) 상태를 정의
    - Modified(수정) : 데이터가 수정된 상태
    - Exclusive(배타) : 이 캐시에만 존재하고 메인 메모리 내용과 동일한 상태
    - Shared(공유) : 둘 이상의 캐시에 데이터가 들어 있고 메모리 내용과 동일한 상태
    - Invalid(무효) : 다른 프로세스가 데이터를 수정해 무효한 상태
    - 핵심 - 멀티 프로세서가 동시에 공유 상태에 있을 수 있다는 것
    - 이 프로토콜에서는 프로세서가 상태를 바꾸겠다는 의사를 브로드캐스팅(방송) ⇒ 공유 메모리 버스를 통해 전기 신호를 보내면 다른 프로세서가 인지
    - MESI 상태 변이 다이어그램
                ![[Untitled 7 1.png]]
        
    - 동시 기록(write-through)
        - 프로세서가 처음 나왔을 때 매번 캐시 연산 결과를 바로 메모리에 기록
        - 메모리 대역폭을 너무 많이 소모하는 등 효율이 낮아 요즘 거의 쓰지 않음
    - 후기록(write-back)
        - 캐시 블록을 교체해도 프로세서가 변경된(더티) 캐시 블록만 메모리에 기록하므로 메인 메모리로 되돌아가는 트래픽이 떨어짐
    - 최대 전송률(brust rate)
        - 메모리 클록 주파수
        - 메모리 버스 폭(보통 64비트)
        - 인터페이스 개수(요즘은 대부분 2개)
    - 캐시 하드웨어 작동 원리를 나타낸 코드
        
        ```Java
        public class Caching {
        	private Final int ARR_SIZE = 2 * 1024 * 1024;
        	private Final int[] testData = new int[ARR_SIZE];
        	
        	private void run(){
        		System.err.println("Start: " + System.currentTimeMillis());
        		for(int i = 0; i < 15_000; i++) {
        			touchEveryLine();
        			touchEveryItem();
        		}
        		
        		System.err.println("Warmup Finished: " + System.currentTimeMillis());
        		System.err.println("Item Line");
        		for(int i = 0; i < 100; i++) {
        			long t0 = System.nanoTime();
        			touchEveryLine();
        			long t1 = System.nanoTime();
        			touchEveryItem();
        			long t2 = System.nanoTime();
        			long elItem = t2 - t1;
        			long elLine = t1 - t0;
        			double diff = elItem - elLine;
        			System.err.println("elItem + " " + elLine + " " + (100 * diff / elLine));
        		}
        	}
        	
        	private void touchEveryItem(){
        		for (int i = 0; i < testData.length; i++) {
        			testData[i]++;
        		}
        	}
        	
        	private void touchEveryLine(){
        		for (int i = 0; i < testData.length; i + 16) {
        			testData[i]++;
        		}
        }
        ```
        
        - 소스 코드에선 touchEveryItem() 이 touchEveryLine() 메서드보다 16배 많은 일을 할 것 같지만 그렇지 X ⇒ 두 메서드의 차이 없음
        - 실제 결과
            
            ![[Untitled 8 1.png]]

## 3.3 최신 프로세서의 특성

### 3.3.1 변환 색인 버퍼(TLB)

- 변환 색인 버퍼(translation lookaside buffer)
    - 가상 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할을 수행
    - 가상 주소 참조를 통해 물리 주소에 액세스하는 빈번한 작업 속도가 매우 빨라짐

### 3.3.2 분기 예측과 추측 실행

- 분기 예측(branch prediction)
    - 프로세서가 조건 분기하는 기준값을 평가하느라 대기하는 현상을 방지
    - 요즘 나온 프로세서는 다단계 명령 파이프라인을 이용해 CPU 1사이클도 여러 개별 단계로 나누어 실행하므로 각기 다른 실행 단계에서 여러 명령이 동시 실행 중일 수도 있음
    - 이 모델에선 조건문을 다 평가하기 전까지 분기 이후 다음 명령을 알 수 없어 분기문 뒤에 나오는 다단계 파이프라인을 비우는 동안 프로세서는 여러 사이클 동안 중지되는데, 이를 막기 위해 프로세서는 트랜지스터를 아낌없이 활용해 가장 발생 가능성이 큰 브랜치를 미리 결정하는 휴리스틱을 생성
    - 추측이 맞으면 CPU는 다음 작업을 진행하고, 틀리면 부분적으로 실행한 명령을 모두 폐기한 후 파이프라인을 비움

### 3.3.3 하드웨어 메모리 모델

- 실행 환경에서 명령의 순서를 자유롭게 변경함으로써 성능 향상
- JMM은 프로세서 타입별로 상이한 메모리 액세스 일관성을 고려해 명시적으로 weak model로 설계
- weak model
    - 다중 프로세서 시스템에서의 I/O를 특정한 순서로 수행될 것을 엄격하게 보장하지 않는 모델
    - 특징
        - 비순차적 실행
            - 프로그램의 실행 중에 메모리 접근(읽기 및 쓰기)이 프로그램 코드에 명시된 순서대로 수행될 필요가 없어, 하드웨어와 컴파일러는 최적화를 위해 이러한 작업을 재배치
        - 성능 최적화
            - 메모리 접근의 순서를 엄격하게 제한하지 않음으로써, 메모리 시스템은 데이터 캐시와 버스 트래픽을 보다 효율적으로 관리할 수 있습니다. 이는 멀티프로세서 시스템에서 성능을 상당히 향상시킬 수 있습니다
        - 동기화 연산
            - Weak consistency model에서는 일반적인 메모리 접근과 동기화 연산(예: 락을 획득하거나 방출하는 연산) 사이의 순서를 엄격하게 구분합니다. 동기화 연산은 일반적인 메모리 접근보다 더 엄격한 순서 규칙을 따르며, 이를 통해 데이터의 일관성을 유지할 수 있습니다

## 3.4 운영체제

- MMU(memory management unit)(메모리 관리 유닛)을 통한 가장 주소 방식과 페이지 테이블은 메모리 액세스 제어의 핵심
    - MMU는 너무 저수준 영역

### 3.4.1 스케줄러
- 프로세스 스케쥴러는 CPU 액세스를 통제 - 실행 큐를 사용
- 스레드의 수명주기
    
    ![[Untitled 9 1.png]]
    
    - 스레드를 시스템 단일 코어로 전달하고, 스케줄러는 할당 시간 끝 무렵에 실행 큐로 스레드를 되돌려 큐의 맨 앞으로 이동해 다시 실행될 때 까지 대기
- OS는 특성상 CPU에서 코드가 실행되지 않는 시간을 유발
- 자신의 할당 시간을 모두 쓴 프로세스는 실행 큐 맨 앞으로 갈 때까지 CPU로 복귀하지 않아 코드가 실행되는 시간보다 기다리는 시간이 더 길어짐 ⇒ 스케줄링 오버헤드 발생

### 3.4.2 시간 문제
- OS마다 타이밍(시간)이 달라진다

### 3.4.3 컨텍스트 교환
- 컨텍스트 교환(context switch)
    - OS 스케줄러가 현재 실행 중인 스레드/테스크를 없애고 대기 중인 다른 스레드/테스크로 대체하는 프로세스
    - 스레드 실행 명령과 스택 상태를 교체하는 모든 일에 연관성이 있음
    - 유저 모드에서 커널 모드로 변경(모드 변경) 등의 컨텍스트 교환은 비싼 작업
    - 커널 모드로 컨텍스트가 교환되면 TLB를 비롯한 다른 캐시까지도 무효화 ⇒ 이 캐시는 시스템 콜 반환 시 다시 채워야 하므로, 커널 모드 교환의 여파는 유저 공간으로 다시 제어권이 넘어가도 이어짐
    - 시스템 콜이 미치는 영향
                ![[Untitled 10 1.png]]
        
    - 가상 동적 공유 객체(virtual dynamically shared object)
        - kernel privileges가 필요없는 시스템 콜의 속도를 높이려고 쓰는 유저 공간의 메모리 영역
        - 타이밍 자료를 빈번하게 액세스하는 자바 애플리케이션에서는 이 방법으로 성능을 끌어올릴 수 있음

## 3.5 단순 시스템 모델
- 단순 시스템 모델 예시
        ![[Untitled 11 1.png]]
## 3.6 기본 감지 전략

### 3.6.1 CPU 사용률
- CPU 사용률은 애플리케이션 성능을 나타내는 핵심 지표
- vmstat
        ![[Untitled 12 1.png]]
    
    - proc 섹션
        - 실행 가능한(r) 프로세스, 블로킹된(b) 프로세스 개수를 나타냄
    - memory 섹션
        - 스왑 메모리(swpd), 미사용 메모리(free), 버퍼로 사용한 메모리(buff), 캐시로 사용한 메모리(cache) 표시
    - swap 섹션
        - 디스크로 교체되어 들어간(스왑-인) 메모리(si), 디스크에서 교체되어 빠져나온 메모리(스왑-아웃) 메모리(so) 정보
    - io 섹션
        - 블록-인(bi), 블록-아웃(bo) 개수는 각각 I/O 장치에서 받은 512바이트 블록, 블록 장치로 보낸 512바이트 블록 개수
    - system 섹션
        - 인터럽트(in) 및 초당 컨텍스트 교환(cs) 횟수
    - cpu 섹션
        - CPU와 직접 연관된 지표를 CPU 사용률로 표기
        - 유저 시간(us), 커널 시간(sy), 유휴 시간(id), 대기 시간(wa), 도둑맞은 시간(st, 가상 머신에 할애된 시간)
- 유저 공간에서 CPU 사용률이 100% 근처도 못 갔는데, 어떤 프로세스에서 컨텍스트 교환 비율이 높게 나타나면 I/O에서 블로킹이 일어났거나, 스레드 락 경합 상황이 벌어졌을 수 있음

### 3.6.2 가비지 수집
- 어떤 시스템에서 CPU 사용률이 아주 높게 나타난다면, GC는 대부분의 시간을 소비하는 주범이 아니다 ⇒ GC 자체는 유저 공간의 CPU 사이클을 소비하되 커널 공간의 사용률에는 영향을 미치지 않는 활동
- 어떤 JVM 프로세스가 유저 공간에서 CPU를 100% 가깝게 사용하고 있다면 GC를 의심해야한다
- JVM에서 GC 로깅은 거의 공짜

### 3.6.3 입출력
- I/O는 다른 OS 파트처럼 분명하게 추상화되어 있는 것이 없음
- I/O가 집중되는 애플리케이션이 하나만 있을 경우, iostat(혹은 vmstat) 같은 툴이 제공하는 기본 카운터(블록-인, 블록-아웃) 기능만으로도 기초 진단 가능
- 커널 바이패스 I/O
    - 커널을 이용해 I/O를 우회하기
                ![[Untitled 13 1.png]]
        
        - 자바에서는 커스텀(네이티브) 라이브러리 사용 필요
        - 아주 유ㅏ용한 패턴으로 초고성능 I/O가 필요한 시스템에서 일반적으로 구현되고 있음

### 3.6.4 기계 공감

> [!important]  
> 자동차 경주 선수가 되려고 엔지니어가 될 필요는 없지만, 기계를 공감할 줄은 알아야 합니다 - 재키 스튜어트  

- 고성능, 저지연이 필수인 분야에서 개발자가 자바/JVM을 효과적으로 활용하려면 JVM이 무엇이고, 하드웨어와 어떻게 상호작용하는지 알아야한다

  

## 3.7 가상화

- 운영체제 가상화
    
    ![[Untitled 14 1.png]]
    
    - 가상화의 특징
        - 가상화 OS에서 실행하는 프로그램은 베어 메탈(비가상화 OS)에서 실행할 때와 동일하게 작동해야 한다
        - Hypervisor는 모든 하드웨어 리소스 액세스를 조정해야한다
        - 가상화 오버헤드는 가급적 작아야 하며 실행 시간의 상당 부분을 차지해선 안 된다
    - 비가상화 시스템에서 OS 커널은 프리빌리지드 모드로 작동하므로 하드웨어를 직접 건드릴 수 있지만, 가상화 시스템에서는 게스트 OS가 하드웨어에 직접 액세스 할 수 없음
    - 이로 인해 대개 프리빌리지드 명렁어를 unprivileged 명령어로 고쳐 씀
    - 컨택스트 교환이 발생하는 도안 지나친 cache flush가 일어나지 않도록 일부 OS 커널의 자료구조를 shadow 해야함

## 3.8 JVM과 운영체제

- JVM은 자바 코드에 공용 인터페이스를 제공해 OS에 독립적인 휴대용 실행 환경을 제공하지만, 스레드 스케줄링 같은 아주 기본적인 서비스도 하부 OS에 반드시 액세스해야한다
- JNI(Java Native Interface)
    - java.lang.object 예시
        
        ```Java
        public Final native Class<?> getClass();
        public natvie int hashCode();
        protected native Object clone() throws CloneNotSupportedException;
        public Final native void nofity();
        public Final native void notifyAll();
        public Final native void wait(long timeout) throws InterruptedException;
        ```
        
    - 핫스팟 호출 스택
        
        ![[Untitled 15 1.png]]
        
        - System.currentTimeMillis() ⇒ 하부 OS 및 하드웨어가 제공하는 서비스를 호출
