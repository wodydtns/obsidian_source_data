- 더 큰 테스트란?
    - 느릴 수 있다
    - 밀페되지 않을 수 있다 → 다른 테스트나 최종 사용자와 자원 및 트래픽 공유하기도 함
    - 비결정적 → 밀폐되지 않은 대규모 테스트라면 다른 테스트나 사용자 상태에 영향을 받을 수 있어 완벽히 결정적이라고 보장하기 거의 불가능
    - 충실성
    - 테스트가 대상의 실제 행위를 얼마나 충실하게 반영했느냐를 나타내는 속성
    - 단위 테스트가 손 대기 어려운 영역
    - 부정확한 테스트 대역
        - 무겁고 테스트하기 어려운 의존성을 제거하는 용도로 테스트 대역을 쓰면 실제와 대역의 동작이 일치하지 않을 가능성이 발생
        - 모의 객체는 실제 구현이 수정될 때 테스트와 테스트 대상 코드도 함께 수정되어야 한다는 신호를 주지 못함
    - 설정 문제
        - 설정 파일에 문제가 있거나, DB에 정의된 상태와 다르게 테스트한 후 프로덕션에 배포하면 사용자에게 심각한 문제를 일으킬 수 있음→ 단위테스트만으로는 이런 호환성 문제를 검증할 수 없음
    - 과부하 시 나타나는 문제
        - 성능, 부하, 스트레스 테스트는 바이너리에 상당한 양의 트래픽을 일으키므로 통상적인 단위 테스트 모델에 녹이기 어려움
    - 예기치 못한 동작, 입력, 부작용
        - 단위 테스트는 작성자가 예살할 수 있는 행위와 입력에 한해서 테스트되기 쉽지만 사용자들은 엔지니어가 예상하지 못한 문제를 찾아내는 경우가 아주 많음
    - 창발적 행위와 진공 효과
        - 단위 테스트가 다루는 범위는 제한적이고, 이 범위 밖에 행위가 바뀌는 건 알아챌 수 없음
        - 단위 테스트는 빠르게 안정적이게끔 설계하기 때문에 실제로 의존하는 바이너리 혹은 현실 세계의 네트워크와 데이터에 연결했을 때 발생할 수 있는 혼돈은 의도적으로 배제
    - 더 큰 테스트를 만들지 않는 이유
        - 높은 신뢰성
            - 결과가 불규칙하면 안되며 유용한 성공|실패 신호를 제공해야 한다
        - 빠른 속도
            - 개발자 워크플로를 방해하지 않을 정도로 빨라야한다
        - 높은 확장성
            - 변경되는 코드에 영향을 받는 모든 테스트를 서브밋 직전과 직후에 효율적으로 실행할 수 있어야 한다
        - 더 큰 테스트가 극복해야 하는 과제
            - 소유권 문제
                - 더 큰 테스트는 다수의 단위에 걸쳐 있으므로 관련된 소유자가 많음 → 소유권이 명확하지 않음
                - 표준화 혹은 표준화 부족
                    - 테스트 수행 방식이 표준화된 방식이 없으므로 인프라 지원이 어려움
- 더 큰 테스트 @구글
    - 더 큰 테스트와 수명
        - 건강한 상태를 오래 유지하는 핵심은 개발 시작 후 며칠 안에 단위 테스트를 만들어 테스트 피라미드를 쌓기 시작하는 것 → 그 다음 수동으로 수행하던 종단간 테스트를 자동화된 통합 테스트로 대체해 피라미드 위층으로 이동
    - 구글 규모에서의 더 큰 테스트
        - 통합 테스트라도 가능한 한 작을수록 좋음
        - 테스트 범위는 SUT의 범위와 관련이 높기 때문에 SUT를 더 작게 만드는 방법을 찾으면 테스트를 더 작게 만드는게 유리
        - SUT : 테스트 대상 - System Under Test
- 큰 테스트의 구조
    - 테스트 대상 시스템
        
        - 대규모 테스트에서 SUT는 항상은 아니지만 하나 이상의 독립된 프로세스에서 수행
        - SUT의 형태 결정 요소
            - 밀폐성 → SUT는 현제 테스트하려는 기능과 관련 없는 구성요소를 사용하거나 상호작용하지 못해야한다 | 밀폐성이 높은 SUT는 동시성 문제나 불규칙한 인프라로부터 영향을 적게 받는다
            - 충실성 → SUT는 테스트 중인 프로덕션 시스템을 충실히 반영해야한다 | 충실성이 높은 SUT는 프로덕션 버전과 유사한 바이너리로 구성
        - 충돌 가능성 요소
            - 단일 프로세스 SUT
                - SUT 전체가 하나의 바이너리로 패키징되고, 나아가 테스트 코드까지 함께 패키징
                - 테스트 -SUT 조합 형태에서 모든 것이 단일 스레드로 실행되면 작은 테스트가 될 수 있지만, 충실성 측면에서 프로덕션의 토폴로지나 설정과 거리가 가장 먼 테스트
            - 단일 머신 SUT
                - SUT는 하나 이상의 독립 바이너리로 구성되며, 테스트도 별도의 바이너리로 만들어진다
            - 다중 머신 SUT
                - SUT를 여러 머신에 분산시킴 → 단일 머신 SUT보다 충실성이 높지만 테스트 규모가 커지면서 여러 머신과 그 사이를 잇는 네트워크가 불안정성을 키워 테스트에 예기치 못한 영향을 줄 가능성이 큼
            - 공유 환경(스테이징&프로덕션)
                - SUT를 독립적으로 실행하는 대신 테스트에서 공유 환경을 직접 사용
            - 하이브리드
                - 어떤 SUT는 혼합된 형태를 보임 → SUT의 구성요소 중 일부는 독립적으로 실행하고, 다른 일부는 공유 환경에서 가동 중인 서비스와 상호작용하는 식일 경우 → 어느 정도 하이브리드화는 피하기 어려움
        - 밀폐된 SUT의 이점
            - 큰 테스트에서 SUT는 테스트 신뢰성을 떨어뜨리고 피드백 시간을 늘리는 주범이 될 수 있음
            - 가장 흔한 대안은 거대한 공유 스테이징 환경을 만들고 테스트를 그 안에서 실행하는 방법
            - 엔지니어가 스테이징 환경에서 사용할 수 있는 시간을 **예약**해두고 그 사람 동안은 계류 중인 코드를 배포하고 테스트를 실행해볼 수 있도록 하는 팀도 있으나 엔지니어 수나 서비스 수가 늘어나면 지속하지 어려움
            - 클라우드에서 격리된 영역을 만들어내거나 머신을 밀폐할 수 있는 환경을 구축하고 그 안에 SUT를 배포하는 방법
        - 문제 경계에서 SUT 크기 줄이기
            - 테스트의 경계
                - UI는 look-and-feel 차원에서 달라지는 경우가 잦아서, 실제 동작은 완전 그대로임에도 UI 테스트를 깨지기 쉽게 만듦
                - UI는 주로 비동기 방식으로 반응하기 때문에 테스트가 어려움
                - 서드파티 의존성 → 서드파티 API를 직접 사용하는 자동 테스트는 권장 X
                - 핵심은 충실성과 비용/신뢰성 사이에서의 균형점과 합리적인 경계를 찾아야한다 → 바이너리 몇 개와 테스트를 묶어 하나의 머신에서 실행할 수 있고, 그 머신이 엔지니어가 매일같이 컴파일, 링크, 단위 테스트하는 바로 그 머신이라면 엔지니어를 위한 가장 편리하고 안정적인 통합 테스트라는 증거
            - 기록/재생 프록시
                - SUT가 의존하지만 보조적인 서비스라면 테스트 대역으로 대체할 수 있다 → 고객 주도 계약 테스트용 프레임워크 → 고객과 서비스 제공자 모두가 지켜야 할 계약(명세)을 정의하고, 이 계약을 토대로 자동화된 테스트를 만들어내는 방식 ⇒ 고객이 서비스의 모의 객체를 정의하며 이 때 어떤 입력을 주면 어떤 결과를 받게 되는지 명시
                    
                - 도구
                    - [Pact contract Testing](https://docs.pact.io/)[
                    - [Spring Cloud Contracts](https://spring.io/projects/spring-cloud-contract)                 
    - 테스트 데이터
        - 대규모 테스트에 필요한 두 가지 데이터
            - 시드 데이터
                - 테스트 개시 시점의 SUT 상태를 반영해 SUT를 사전 초기화해주는 데이터
            - 테스트 트래픽
                - 테스트 수행 과정에서 SUT로 보내는 데이터
            - 도메인 데이터
                - 환경 구성용으로 미리 테이블들에 채워져있는 데이터
            - 현실적인 기준선
                - 현실적인 SUT가 되려면 품질과 양적 측면 모두에서 현실적인 데이터셋이 기본으로 갖춰져있어야 함
            - 데이터 기록 API
                - 손수 가공한 데이터
                    - 작은 테스트처럼 더 큰 테스트용 데이터도 사람이 직접 만들 수 있음
                - 복사한 데이터
                    - 프로덕션 시스템으로부터 데이터를 복사해서 사용
                - 샘플링한 데이터
                    - 표본을 추출해 데이터 사용
    - 검증
        - 수동 검증
            - 사람이 SUT와 직접 상호작용하며 올바르게 동작하는지 확인
            - 테스트 계획에 정의된 조치대로 일관되게 회귀 테스트를 수행하거나 색다른 상호작용 시나리오를 찾아 잠재된 새로운 결함을 찾는 탐색적 테스팅 용도
        - 단정문
            - 시스템이 의도된 대로 동작하는지 명확히 검사하는 검증 방식
            
            ```java
            assertThat(response.Contains("Colossal Cave"))
            ```
        - A/B 비교
            - A/B 테스트는 두 벌의 SUT를 구동시켜 똑같은 데이터를 보낸 다음 결과를 비교하는 검증 방식
- 더 큰 테스트 유형
    - 구글에서 사용하는 큰 테스트 종류
        - 하나 이상의 바이너리에 대한 기능 테스트
        - 브라우저와 기기 테스트
        - 성능, 부하, 스트레스 테스트
        - 배포 설정 테스트
        - 탐색적 테스팅
        - A/B 차이(회귀) 테스트
        - 사용자 인수 테스트
        - 프로버와 카나리 분석
        - 재해 복구와 카오스 엔지니어링
        - 사용자 평가
    - 소프트웨어 설계의 일환으로 테스트 계획 초안도 작성
    - 하나 혹은 상호작용하는 둘 이상의 바이너리 기능 테스트
        - 이 테스트의 특성
            - SUT : 밀폐된 단일 머신 or 격리된 클라우드에 배포
            - 데이터 : 수동 생성
            - 검증 방식 : 단정문
        - 여러 바이너리가 상호작용하는 기능이라면 바이너리가 하나일 때보다 테스트하기가 훨씬 복잡
    - 브라우저와 기기 테스트
        - 웹 UI나 모바일 애플리케이션 테스트 역시 하나 이상의 바이너리와 상호작용하는 기능 테스트의 한 형태
    - 성능, 부하, 스트레스 테스트
        - 이 테스트의 특성
            - SUT : 격리된 클라우드에 배포
            - 데이터 : 수동 생성 혹은 프로덕션 환경에서 복사
            - 검증 방식 : 차이 비교(성능 지표)
        - 정의상 주로 바이너리 검증용에 쓰이는 다중 스레드 테스트
        - 성능 저하나 시스템이 목표한 최대 트래픽을 감장할 수 있는지를 확인하는 데 필수적인 테스트
        - 복잡한 동작은 시스템 전체와 관련 있으므로 가능한 한 프로덕션과 비슷한 환경에서 수행
        - 배치 토폴로지 → 다양한 바이너리가 컴퓨터 네트워크에 배치되는 형태
    - 배포 설정 테스트
        - SUT : 밀폐된 단일 머신 or 격리된 클라우드에 배포
        - 데이터 : 없음
        - 검증 방식 : 단정문(비정상 종료는 하지 않음)
        - 스모크 테스트 → 본격적인 테스트에 앞서 테스트를 진행해도 되는 상황인지를 확인해보는 용도의 테스트
        - SUT가 제대로 구동되는 테스트 통과 | 그렇지 않으면 실패
    - 탐색적 테스팅
        - SUT : 프로덕션 혹은 공유 스테이징 환경에 배포
        - 데이터 : 프로덕션에서 수집 혹은 알려진 테스트 시나리오 데이터
        - 검증 방식 : 수동
        - 정의 : 새로운 사용자 시나리오를 시도해가며 의문스러운 동작을 찾는 수동 테스트
        - 새로운 시스템은 물론 이미 서비스 중인 시스템에서도 예상치 못한 동작과 부작용을 발견해낼 수 있어 유용
        - 테스트 커버리지를 높이고, 버그를 찾게 되면 해당 경로를 자동화된 기능 테스트로 만들어 활용 (퍼즈 테스트와 유사)
        - 퍼즈 테스트 : 정상적이지 않은 혹은 무작위의 데이터를 입력해 수행하는 테스트
        - 한계
            - 수통 테스트를 수행하려면 사람이 시간을 써야한다
        - 버그 파티
            - 엔지니어 뿐만 아니라 모든 사람이 모여 제품을 수동으로 테스트
            - 버그 파티마다 집중적으로 살펴볼 영역이나 시작점을 미리 정해둘 수 있음
    - A/B 차이 회귀 테스트
        - SUT : 두 개의 격리된 클라우드에 배포
        - 데이터 : 대체로 프로덕션 환경에서 복사한 혹은 샘플링한 데이터
        - 검증 방식 : A/B 차이 비교
        - 구버전 제품과 신버전 제품의 공개 API로 트래픽을 보내 둘의 반응이 어떻게 다른지 비교
        - 난관
            - 인가
                - 어떤 유의미한 차이가 생겼는 지 알아챌 만큼 결과 이해 필요
            - 노이즈
                - 예상치 못한 노이즈 발생 시 다시 사람이 직접 조사해야함
            - 커버리지
                - 충분히 의미 있는 트래픽 생성이 어려울 수 있음
                - 특이 케이스를 찾아낼 수 있는 테스트 데이터 관리의 어려움
            - 설정
                - sut 하나로 설정하고 관리하기 어려움
    - 사용자 인수 테스트(UAT)
        - SUT : 밀폐된 단일 머신 혹은 격리된 클라우드에 배포
        - 데이터 : 수동 생성
        - 검증 방식 : 단정문
        - 공개 API를 통해 제품을 조작하면서 특정 사용자 여정이 의도한 대로 이루어지는 지를 보장하는 테스트
    - 프로버와 카나리 분석
        - SUT : 프로덕션에 배포
        - 데이터 : 프로덕션에 수집
        - 검증 방식 : 단정문과 지표상의 A/B 차이
        - 프로덕션 환경 자체가 건강함을 보장하는 수단
        - 프로버 : 프로덕션 환경을 대상으로 단정문을 수행하는 기능 테스트 → 잘 알려지고 결정적인 읽기 전용 동작이 검증대상
        - 카나리 분석 : 프로버와 비슷, 신버전을 프로덕션 환경에 언제 배포할지가 주된 관심사
        - 한계
            - 프로버가 만약 값을 변경하는 동작(쓰기)을 수행하면 프로덕션의 상태가 변경됨 → 그 결과로 **비결정적인 동작과 단정문 실패 & 다음번 쓰기 시 실패 & 사용자에게 영향을 주는 부수 효과** 중 하나로 귀결
    - 재해 복구와 카오스 엔지니어링
        - SUT : 프로덕션에 배포
        - 데이터 : 프로덕션에서 수집 혹은 사용자가 제작(결함 주입)
        - 검증 방식 : 수동 및 지표상의 A/B 차이
        - 시스템이 예기치 못한 변경이나 실패에도 얼마나 굳건히 대응하는가를 확인하는 테스트
        - 카오스 엔지니어링 : 시스템에 꾸준히 결함을 심어서 무슨 일이 벌어지는 지 관찰하는 테스트
        - 한계
            - 프로덕션 환경에서 이루어지므로 문제를 파악한 것 == 최종 사용자에게 영향을 주고 있는 중이라는 의미
            - 비용이 많이 듦
    - 사용자 평가
        - SUT : 프로덕션에 배포
        - 데이터 : 프로덕션에서 수집
        - 검증 방식 : 수동 및 지표상의 A/B 차이
        - 개밥 주기(dogfooding 사내 시험 적용)
            - 공개 대상을 제한하는 식으로 프로덕션 환경에서 일부 사용자가 새로운 기능을 맛보도록 함
        - 실험
            - 새로운 기능을 일부 사용자에게 제공하되 그 사실을 알리지 않고 진행 → 이후 원하는 지표를 기준으로 실험집단과 통제집단 비교
        - 평가자 감정
            - 변화된 결과를 인간 평가자들에게 보여주고 어느것이 나은지와 왜 그런지를 선택하게 함 → 변경이 긍정적, 중립적, 부정적인지 결정하는데 사용
- 큰 테스트와 개발자 워크플로
    - 큰 테스트 작성하기
        - 명확한 라이브러리, 문서자료, 예시 코드 참조하기
        - 비용 확인 필요
    - 큰 테스트 수행하기
        - 테스트 속도 개선하기
            - 테스트 범위를 축하고, 더 작은 테스트로 나눠 병렬로 수행
            - 테스트를 실제 이용자와 동일하게 작성
                - 마이크로초 단위로 상태를 폴링(polling)하면서 원하는 작업이 완료됐는 지 확인
                - 이벤트 핸들러를 구현
                - 이벤트 완료를 알려주는 알림 시스템에 등록
            - 내부 시스템 타임아웃과 지연 낮추기
                - 프로덕션 코드가 타임아웃 값을 하드코딩해 사용하거나 sleep()을 사용한다면 테스트를 수행할 때 타임아웃 값을 줄일 수 있게 수정
            - 테스트 빌드 시간 최적화
                - 테스트 하는 것에 따라 빌드의 크기를 조정 하는 등의 빌드 시간 최적화 필요
        - 불규칙한 결과에서 벗어나기
            - 테스트 범위 좁히기
            - 때에 따라 테스트 속도와 불규칙한 결과 사이에서 절충점 찾기
            - 타임아웃 때문에 발생하는 불규칙하게 발생하는 일시적인 문제인지 아니면 진짜로 코드에 문제가 있는 것인지 확실하게 구분해야함
        - 이해되는 테스트 만들기
            - 무엇이 실패했는지 명확히 알려주기
            - 최소한의 노력으로 근본 원인을 찾을 수 있도록 하기
                - 호출 체인을 추적할 수 있도록 하기
                - 범위를 좁힐 수 있는 자동화
            - 지원 정보 및 연락처 정보를 제공
    - 큰 테스트의 소유권
        - 특정 프로젝트의 구성요소들을 검증하는 통합 테스트면 소유권은 프로젝트 리드가 맡는 것이 좋음
        - 기능에 중점을 준 테스트라면 해당 기능의 소유자가 테스트도 소유
        - 일반적인 코드 소유권 → 해당 테스트 코드의 소유자 == 테스트 소유자
        - 테스트별 애너테이션 → annotation으로 각 메서드의 테스트 소유자 명시